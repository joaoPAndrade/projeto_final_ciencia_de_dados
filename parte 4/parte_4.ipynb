{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b63d863a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report,\n",
        "    mean_squared_error, r2_score, f1_score\n",
        ")\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4bd429b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../dados_limpos/dados.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "779bb2a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df['DatGeracaoConjuntoDados'] = pd.to_datetime(df['DatGeracaoConjuntoDados'], errors='coerce')\n",
        "df['DatVencimentoTitulo']     = pd.to_datetime(df['DatVencimentoTitulo'], errors='coerce')\n",
        "df['DatIncidenciaMultaMora']  = pd.to_datetime(df['DatIncidenciaMultaMora'], errors='coerce')\n",
        "\n",
        "df['Codcvnarr']      = pd.to_numeric(df['Codcvnarr'], errors='coerce').astype('Int64')\n",
        "\n",
        "df['NumCPFCNPJ'] = (\n",
        "    df['NumCPFCNPJ']\n",
        "    .astype(str)\n",
        "    .str.replace(r'\\D+', '', regex=True)\n",
        "    .replace({'', 'nan', 'None'}, np.nan)\n",
        ")\n",
        "\n",
        "string_cols = [\n",
        "    'AnmArrecadacao',\n",
        "    'SigNomAgente',\n",
        "    'DscSituacaoArrecadacao',\n",
        "    'DscSituacaoCredito'\n",
        "]\n",
        "\n",
        "for col in string_cols:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "        .astype(str)\n",
        "        .str.strip()\n",
        "        .replace({'nan': np.nan, 'None': np.nan})\n",
        "    )\n",
        "\n",
        "for col in string_cols:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "    \n",
        "df['QtdDiasEmAtraso'] = (\n",
        "    pd.to_numeric(df['QtdDiasEmAtraso'], errors='coerce')\n",
        "      .astype('Int64')\n",
        ")\n",
        "\n",
        "def to_float_br(series):\n",
        "    return (series.astype(str)\n",
        "                  .str.strip()\n",
        "                  .str.replace('.', '', regex=False)\n",
        "                  .str.replace(',', '.', regex=False)\n",
        "                  .replace(['', 'nan', 'None'], np.nan)\n",
        "                  .astype(float))\n",
        "\n",
        "df['VlrPcpPrvArr']      = to_float_br(df['VlrPcpPrvArr'])\n",
        "df['VlrTotPvrArr']      = to_float_br(df['VlrTotPvrArr'])\n",
        "df['VlrTotPagArr']      = to_float_br(df['VlrTotPagArr'])\n",
        "df['VlrTotDifPvrPagArr'] = to_float_br(df['VlrTotDifPvrPagArr'])\n",
        "df['VlrSelic']          = to_float_br(df['VlrSelic'])\n",
        "\n",
        "df['VlrPcpPrvArr']       = df['VlrPcpPrvArr'].round(2)\n",
        "df['VlrTotPvrArr']       = df['VlrTotPvrArr'].round(2)\n",
        "df['VlrTotPagArr']       = df['VlrTotPagArr'].round(2)\n",
        "df['VlrTotDifPvrPagArr'] = df['VlrTotDifPvrPagArr'].round(2)\n",
        "df['VlrSelic']           = df['VlrSelic'].round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0364c129",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 415065 entries, 0 to 415064\n",
            "Data columns (total 21 columns):\n",
            " #   Column                   Non-Null Count   Dtype         \n",
            "---  ------                   --------------   -----         \n",
            " 0   DatGeracaoConjuntoDados  415065 non-null  datetime64[ns]\n",
            " 1   Codcvnarr                415065 non-null  Int64         \n",
            " 2   AnmArrecadacao           415065 non-null  category      \n",
            " 3   DatVencimentoTitulo      415065 non-null  datetime64[ns]\n",
            " 4   DatIncidenciaMultaMora   415065 non-null  datetime64[ns]\n",
            " 5   QtdDiasEmAtraso          415065 non-null  Int64         \n",
            " 6   NumCPFCNPJ               415065 non-null  object        \n",
            " 7   SigNomAgente             415065 non-null  category      \n",
            " 8   DscSituacaoArrecadacao   415065 non-null  category      \n",
            " 9   DscSituacaoCredito       415065 non-null  category      \n",
            " 10  VlrPcpPrvArr             415065 non-null  float64       \n",
            " 11  VlrTotPvrArr             415065 non-null  float64       \n",
            " 12  VlrTotPagArr             415065 non-null  float64       \n",
            " 13  VlrTotDifPvrPagArr       415065 non-null  float64       \n",
            " 14  VlrSelic                 415065 non-null  float64       \n",
            " 15  AnoArrec                 415065 non-null  int64         \n",
            " 16  MesArrec                 415065 non-null  int64         \n",
            " 17  fatura_paga              415065 non-null  int64         \n",
            " 18  fatura_atrasado          415065 non-null  int64         \n",
            " 19  fatura_nao_paga          415065 non-null  int64         \n",
            " 20  TrimestreVencimento      415065 non-null  int64         \n",
            "dtypes: Int64(2), category(4), datetime64[ns](3), float64(5), int64(6), object(1)\n",
            "memory usage: 57.2+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d3db643a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['DatGeracaoConjuntoDados', 'Codcvnarr', 'AnmArrecadacao',\n",
              "       'DatVencimentoTitulo', 'DatIncidenciaMultaMora', 'QtdDiasEmAtraso',\n",
              "       'NumCPFCNPJ', 'SigNomAgente', 'DscSituacaoArrecadacao',\n",
              "       'DscSituacaoCredito', 'VlrPcpPrvArr', 'VlrTotPvrArr', 'VlrTotPagArr',\n",
              "       'VlrTotDifPvrPagArr', 'VlrSelic', 'AnoArrec', 'MesArrec', 'fatura_paga',\n",
              "       'fatura_atrasado', 'fatura_nao_paga', 'TrimestreVencimento'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c38795d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['prop_pago'] = df['VlrTotPagArr'] / df['VlrTotPvrArr']\n",
        "df['prop_pago'] = df['prop_pago'].fillna(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641f928d",
      "metadata": {},
      "source": [
        "### Implementação dos modelos de machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a0ad075",
      "metadata": {},
      "source": [
        "# primeiro"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea9b076",
      "metadata": {},
      "source": [
        "Foi necessário dropar todas essas colunas para determinar se o pagamento da fatura irá atrasar, essas features causam data leak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff739993",
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_drop = [\n",
        "    'fatura_atrasado',\n",
        "    'fatura_paga',\n",
        "    'fatura_nao_paga',\n",
        "    'QtdDiasEmAtraso',\n",
        "    'VlrTotPvrArr',\n",
        "    'VlrTotPagArr',\n",
        "    'VlrTotDifPvrPagArr',\n",
        "    'DscSituacaoArrecadacao',\n",
        "    'DscSituacaoCredito',\n",
        "    'Codcvnarr',\n",
        "    'NumCPFCNPJ',\n",
        "    'DatIncidenciaMultaMora',\n",
        "    'DatVencimentoTitulo',\n",
        "    'DatGeracaoConjuntoDados'\n",
        "]\n",
        "\n",
        "X = df.drop(columns=cols_to_drop)\n",
        "y = df['fatura_atrasado']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "53af89a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical = X.select_dtypes(include=['float64','int64','Int64']).columns\n",
        "categorical = X.select_dtypes(include=['category']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bc27aca5",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "d9b99df6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia baseline: 0.9908448074397986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.52      0.64      1300\n",
            "           1       0.99      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           0.99     83013\n",
            "   macro avg       0.91      0.76      0.82     83013\n",
            "weighted avg       0.99      0.99      0.99     83013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "log_reg = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=100))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "pred = log_reg.predict(X_test)\n",
        "\n",
        "print(\"Acurácia baseline:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "f1 = f1_score(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "67a298c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia baseline: 0.9908448074397986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.52      0.64      1300\n",
            "           1       0.99      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           0.99     83013\n",
            "   macro avg       0.91      0.76      0.82     83013\n",
            "weighted avg       0.99      0.99      0.99     83013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "log_reg = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=150))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "pred = log_reg.predict(X_test)\n",
        "\n",
        "print(\"Acurácia baseline:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "f1 = f1_score(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "730db106",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia baseline: 0.9908448074397986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.52      0.64      1300\n",
            "           1       0.99      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           0.99     83013\n",
            "   macro avg       0.91      0.76      0.82     83013\n",
            "weighted avg       0.99      0.99      0.99     83013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "log_reg = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "pred = log_reg.predict(X_test)\n",
        "\n",
        "print(\"Acurácia baseline:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n",
        "f1 = f1_score(y_test, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81b1c972",
      "metadata": {},
      "source": [
        "Alterando o parametro de maximo de iterações é possível observar que não houve mudanças nos valores da classificação de não atraso pois a base de dados é desbalanceada, assim o modelo aprende a chutar todos os registros como atraso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "140135c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SigNomAgente 0.017551467842386193\n",
            "VlrSelic 0.001214267644826772\n",
            "AnoArrec 0.000399937359208824\n",
            "AnmArrecadacao 0.0003517521352077946\n",
            "VlrPcpPrvArr 0.00014937419440332888\n",
            "TrimestreVencimento 3.854817920088127e-05\n",
            "prop_pago 0.0\n",
            "MesArrec -6.0231530001253476e-05\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    log_reg, X_test, y_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab6d1bf4",
      "metadata": {},
      "source": [
        "Os valores mostram que SigNomAgente é, de longe, a variável mais relevante para prever atraso, enquanto Selic, AnoArrec e outras contribuem muito pouco, indicando impacto quase nulo no modelo. Em resumo, o risco de atraso depende essencialmente do agente, e as demais variáveis têm influência mínima na classificação.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "f3dc20eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia RF: 0.996952284581933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.84      0.90      1300\n",
            "           1       1.00      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           1.00     83013\n",
            "   macro avg       0.98      0.92      0.95     83013\n",
            "weighted avg       1.00      1.00      1.00     83013\n",
            "\n",
            "F1 Score RF: 0.9984534979675418\n"
          ]
        }
      ],
      "source": [
        "rf_cls = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', RandomForestClassifier(n_estimators=100))\n",
        "])\n",
        "\n",
        "rf_cls.fit(X_train, y_train)\n",
        "pred_rf = rf_cls.predict(X_test)\n",
        "\n",
        "print(\"Acurácia RF:\", accuracy_score(y_test, pred_rf))\n",
        "print(classification_report(y_test, pred_rf))\n",
        "print(\"F1 Score RF:\", f1_score(y_test, pred_rf))\n",
        "f1 = f1_score(y_test, pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "22fb0d24",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia RF: 0.9968438678279306\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.83      0.89      1300\n",
            "           1       1.00      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           1.00     83013\n",
            "   macro avg       0.98      0.92      0.95     83013\n",
            "weighted avg       1.00      1.00      1.00     83013\n",
            "\n",
            "F1 Score RF: 0.9983984742716726\n"
          ]
        }
      ],
      "source": [
        "rf_cls = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', RandomForestClassifier(n_estimators=150))\n",
        "])\n",
        "\n",
        "rf_cls.fit(X_train, y_train)\n",
        "pred_rf = rf_cls.predict(X_test)\n",
        "\n",
        "print(\"Acurácia RF:\", accuracy_score(y_test, pred_rf))\n",
        "print(classification_report(y_test, pred_rf))\n",
        "print(\"F1 Score RF:\", f1_score(y_test, pred_rf))\n",
        "f1 = f1_score(y_test, pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "ab2f3cad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia RF: 0.9969161456639322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.84      0.89      1300\n",
            "           1       1.00      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           1.00     83013\n",
            "   macro avg       0.98      0.92      0.95     83013\n",
            "weighted avg       1.00      1.00      1.00     83013\n",
            "\n",
            "F1 Score RF: 0.998435169564048\n"
          ]
        }
      ],
      "source": [
        "rf_cls = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', RandomForestClassifier(n_estimators=180))\n",
        "])\n",
        "\n",
        "rf_cls.fit(X_train, y_train)\n",
        "pred_rf = rf_cls.predict(X_test)\n",
        "\n",
        "print(\"Acurácia RF:\", accuracy_score(y_test, pred_rf))\n",
        "print(classification_report(y_test, pred_rf))\n",
        "print(\"F1 Score RF:\", f1_score(y_test, pred_rf))\n",
        "f1 = f1_score(y_test, pred_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23dd806a",
      "metadata": {},
      "source": [
        "Podemos observar que aumentar o numero de arvores diminuiu ligeiramente o F1-Score. O contra desse modelo é que seu treinamentio demora muito tempo para finalizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "a7085fc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SigNomAgente 0.026728343753388017\n",
            "VlrSelic 0.009345524195005606\n",
            "AnoArrec 0.002681507715658982\n",
            "VlrPcpPrvArr 0.001746714370038438\n",
            "AnmArrecadacao 0.0016840735788370641\n",
            "prop_pago 0.0\n",
            "MesArrec -7.2277836001610755e-06\n",
            "TrimestreVencimento -4.095744040091276e-05\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    rf_cls, X_test, y_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cffe1ca",
      "metadata": {},
      "source": [
        "As variaveis mais influentes para classificação foram o ano da arrecadação e o nome do agente"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c49d3b30",
      "metadata": {},
      "source": [
        "-- Conjunto de parametros reduzidos para diminuir o tempo do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0572905",
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_rf = {\n",
        "    \"model__n_estimators\": [150, 250],#\n",
        "    \"model__max_depth\": [None, 5, 10],\n",
        "    \"model__min_samples_split\": [2, 5],\n",
        "    \"model__min_samples_leaf\": [1, 2],\n",
        "    \"model__max_features\": [\"sqrt\"]\n",
        "}\n",
        "\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator=Pipeline(steps=[\n",
        "        ('prep', preprocessor),\n",
        "        ('model', RandomForestClassifier(random_state=42))\n",
        "    ]),\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring=\"f1\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros:\", grid_rf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ff7798",
      "metadata": {},
      "source": [
        "Otimização de hiperparâmetros com randomForest foi muito pesada para executar e não foi possível esperar o experimento terminar de executar. A execução de 1 combinação demora mais de 30 minutos para treinar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "5625f1f3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia XGBClassifier: 0.9946634864418826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.69      0.80      1300\n",
            "           1       1.00      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           0.99     83013\n",
            "   macro avg       0.98      0.85      0.90     83013\n",
            "weighted avg       0.99      0.99      0.99     83013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_cls = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', XGBClassifier(\n",
        "        eval_metric='logloss',\n",
        "        tree_method='hist'\n",
        "    ))\n",
        "])\n",
        "\n",
        "xgb_cls.fit(X_train, y_train)\n",
        "pred_xgb = xgb_cls.predict(X_test)\n",
        "\n",
        "print(\"Acurácia XGBClassifier:\", accuracy_score(y_test, pred_xgb))\n",
        "print(classification_report(y_test, pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0831c615",
      "metadata": {},
      "source": [
        "O resultado do XGBoost foi inferior a RandomForest e superior ao logistic regression, porém seu tempo de treino foi muito menor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c53682f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Melhores hiperparâmetros XGB: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 8, 'model__n_estimators': 200, 'model__subsample': 1.0}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid_xgb = {\n",
        "    \"model__n_estimators\": [200],\n",
        "    \"model__max_depth\": [4, 8],\n",
        "    \"model__learning_rate\": [0.03, 0.1],\n",
        "    \"model__subsample\": [0.8, 1.0],\n",
        "    \"model__colsample_bytree\": [0.8]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(\n",
        "    estimator=Pipeline(steps=[\n",
        "        ('prep', preprocessor),\n",
        "        ('model', XGBClassifier(\n",
        "            eval_metric='logloss',\n",
        "            tree_method='hist'\n",
        "        ))\n",
        "    ]),\n",
        "    param_grid=param_grid_xgb,\n",
        "    scoring='f1',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros XGB:\", grid_xgb.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c4b336c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia XGBClassifier: 0.9951212460698927\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.70      0.82      1300\n",
            "           1       1.00      1.00      1.00     81713\n",
            "\n",
            "    accuracy                           1.00     83013\n",
            "   macro avg       0.99      0.85      0.91     83013\n",
            "weighted avg       1.00      1.00      0.99     83013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_xgb_reg = grid_xgb.best_estimator_\n",
        "\n",
        "pred = best_xgb_reg.predict(X_test)\n",
        "\n",
        "print(\"Acurácia XGBClassifier:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c95b850",
      "metadata": {},
      "source": [
        "A aplicação de otimização de hiperparametros no modelo de XGBoost não trouxe ganhos signigicativos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35ebc88a",
      "metadata": {},
      "source": [
        "Para tarefa de classificação de atraso na fatura o modelo de random forest obteve os melhores resultados e XGBoost obteve o melhor desempenho/tempo de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf196114",
      "metadata": {},
      "source": [
        "### **1. Modelo Baseline – LogisticRegression**\n",
        "\n",
        "| Modelo                        | Precisão | Recall   | F1-Score |\n",
        "| ----------------------------- | -------- | -------- | -------- |\n",
        "| LogisticRegression (baseline) | **0.91** | **0.76** | **0.82** |\n",
        "\n",
        "### **2. RandomForestClassifier**\n",
        "\n",
        "| Modelo                 | Precisão | Recall   | F1-Score |\n",
        "| ---------------------- | -------- | -------- | -------- |\n",
        "| RandomForestClassifier | **0.98** | **0.92** | **0.95** |\n",
        "\n",
        "### **3. XGBClassifier (antes da otimização)**\n",
        "\n",
        "| Modelo        | Precisão | Recall   | F1-Score |\n",
        "| ------------- | -------- | -------- | -------- |\n",
        "| XGBClassifier | **0.98** | **0.85** | **0.90** |\n",
        "\n",
        "### **4. XGBClassifier (após otimização de hiperparâmetros)**\n",
        "\n",
        "| Modelo                 | Precisão | Recall   | F1-Score |\n",
        "| ---------------------- | -------- | -------- | -------- |\n",
        "| XGBClassifier (tuning) | **0.99** | **0.85** | **0.91** |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130de999",
      "metadata": {},
      "source": [
        "# segundo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094d1cf7",
      "metadata": {},
      "source": [
        "Essas são as colunas que são necessário dropar para não haver data leak"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "56dd9da2",
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas_para_remover = [\n",
        "    'VlrTotDifPvrPagArr',\n",
        "    'VlrTotPvrArr',\n",
        "    'VlrTotPagArr',\n",
        "    'fatura_paga',\n",
        "    'fatura_atrasado',\n",
        "    'fatura_nao_paga',\n",
        "    'NumCPFCNPJ',\n",
        "    'DatGeracaoConjuntoDados',\n",
        "    'DatIncidenciaMultaMora',\n",
        "    'AnoArrec',\n",
        "    'MesArrec',\n",
        "    'TrimestreVencimento',\n",
        "    'prop_pago'\n",
        "]\n",
        "df_sample = df.sample(frac=0.20, random_state=42)\n",
        "\n",
        "X2 = df_sample.drop(columns=colunas_para_remover)\n",
        "y2 = df_sample['VlrTotDifPvrPagArr']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96cb3297",
      "metadata": {},
      "source": [
        "O processor para transformação dos dados precisa ser alterados pois as colunas de X e X2 são diferentes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f63b94",
      "metadata": {},
      "source": [
        "Foi necessário fazer uma amostragem dos dados pois o conjunto de dados era muito grande para ser carregado para treinar o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cf659971",
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical = X2.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical = X2.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical),\n",
        "        ('cat', Pipeline([\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "            ('svd', TruncatedSVD(n_components=100))\n",
        "        ]), categorical)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ecf24f32",
      "metadata": {},
      "outputs": [],
      "source": [
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "987a2077",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE (LinearRegression): 2.7485636071557513e+30\n",
            "R² (LinearRegression): 0.003664312908851053\n"
          ]
        }
      ],
      "source": [
        "lin_reg = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "lin_reg.fit(X2_train, y2_train)\n",
        "pred = lin_reg.predict(X2_test)\n",
        "\n",
        "print(\"MSE (LinearRegression):\", mean_squared_error(y2_test, pred))\n",
        "print(\"R² (LinearRegression):\", r2_score(y2_test, pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a8d9b1c",
      "metadata": {},
      "source": [
        "O erro do modelo foi muito alto e o modelo foi péssimo em explicar o dataset, isso se deve a outliers que existem no dataset que não podem ser explicados se são uma tarifa que possui um valor muito alto e não foi paga ou juros foi muito alto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2d6dd7ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AnmArrecadacao 0.005696764007923405\n",
            "DscSituacaoArrecadacao 0.003963784427457951\n",
            "Codcvnarr 0.0014168726208713344\n",
            "DscSituacaoCredito 0.0012181197080608941\n",
            "QtdDiasEmAtraso 0.000810225155706501\n",
            "SigNomAgente 0.0004225937624048326\n",
            "VlrSelic 3.650993935888636e-06\n",
            "DatVencimentoTitulo 0.0\n",
            "VlrPcpPrvArr -1.219061600548077e-05\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    lin_reg, X2_test, y2_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X2.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cb632d9",
      "metadata": {},
      "source": [
        "A influência de todas as variáveis para o problema foram muito baixas, com ano da arrecadação sendo a mais influênte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "29f8e6dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE (XGBRegressor): 2.6029039949137874e+30\n",
            "R² (XGBRegressor): 0.05646493555651311\n"
          ]
        }
      ],
      "source": [
        "xgb_reg = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', XGBRegressor(tree_method='hist', max_depth=5, learning_rate=0.1))\n",
        "])\n",
        "\n",
        "xgb_reg.fit(X2_train, y2_train)\n",
        "pred_xgb = xgb_reg.predict(X2_test)\n",
        "\n",
        "print(\"MSE (XGBRegressor):\", mean_squared_error(y2_test, pred_xgb))\n",
        "print(\"R² (XGBRegressor):\", r2_score(y2_test, pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed76b895",
      "metadata": {},
      "source": [
        "A aplicação do XGBoost melhorou ligeiramente o desempenho na tarefa de prever a diferença entre o valor efetivamente pago e o valor previsto com uma diferença mínima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "81dcba5e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AnmArrecadacao 0.2628420743306662\n",
            "QtdDiasEmAtraso 0.1915609974791\n",
            "VlrSelic 0.16212822701351198\n",
            "DscSituacaoArrecadacao 0.06851924594624267\n",
            "DscSituacaoCredito 0.04319117578459393\n",
            "SigNomAgente 0.03692088512596481\n",
            "Codcvnarr 0.002487516787381283\n",
            "DatVencimentoTitulo 0.0\n",
            "VlrPcpPrvArr -0.006537429890174163\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    xgb_reg, X2_test, y2_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X2.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6590ad",
      "metadata": {},
      "source": [
        "Para o modelo do XGBoost a variável mais importa para o problema foi o AnmArrecadacao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "cd15a839",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Melhores hiperparâmetros XGBRegressor: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.05, 'model__max_depth': 4, 'model__n_estimators': 200, 'model__subsample': 0.8}\n",
            "MSE após tuning: 2.5629922196568756e+30\n",
            "R² após tuning: 0.07093268369961414\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid_xgb_reg = {\n",
        "    \"model__n_estimators\": [200, 400],\n",
        "    \"model__max_depth\": [4, 6],\n",
        "    \"model__learning_rate\": [0.05, 0.1],\n",
        "    \"model__subsample\": [0.8],\n",
        "    \"model__colsample_bytree\": [0.8]\n",
        "}\n",
        "\n",
        "grid_xgb_reg = GridSearchCV(\n",
        "    estimator=Pipeline(steps=[\n",
        "        ('prep', preprocessor),\n",
        "        ('model', XGBRegressor(\n",
        "            tree_method='hist',\n",
        "            eval_metric='rmse'\n",
        "        ))\n",
        "    ]),\n",
        "    param_grid=param_grid_xgb_reg,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_xgb_reg.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros XGBRegressor:\", grid_xgb_reg.best_params_)\n",
        "best_xgb_reg = grid_xgb_reg.best_estimator_\n",
        "\n",
        "pred_xgb_tuned = best_xgb_reg.predict(X2_test)\n",
        "\n",
        "print(\"MSE após tuning:\", mean_squared_error(y2_test, pred_xgb_tuned))\n",
        "print(\"R² após tuning:\", r2_score(y2_test, pred_xgb_tuned))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c16a5d68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE médio (CV): 2.488458303130407e+30\n",
            "Desvio padrão: 2.722938114453816e+29\n"
          ]
        }
      ],
      "source": [
        "cv_scores_xgb = cross_val_score(\n",
        "    best_xgb_reg,\n",
        "    X2_train,\n",
        "    y2_train,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"MSE médio (CV):\", -cv_scores_xgb.mean())\n",
        "print(\"Desvio padrão:\", cv_scores_xgb.std())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf0e34f6",
      "metadata": {},
      "source": [
        "Houve uma melhora em aplicar validação cruzada e otimização de hiperparametros diminuindo o erro médio e aumentando a explicabilidade do dataset pelo modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43d8d5fc",
      "metadata": {},
      "source": [
        "Aplicando o cross validation no modelo de XGBoost observamos que o erro do modelo continua muito alto. Além disso a explicabilidade do dataset pelo modelo permanece baixa para o problema e o desvio padrão é muito alto ao prevermos o nosso problema."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70614b7b",
      "metadata": {},
      "source": [
        "Devido a melhora do erro médio e o modelo em explicar o dataset o modelo que se saiu melhor foi o XGBoost que também não teve um tempo de treino de mais de 5 min.\n",
        "Nos experimentos inicialmente foi aplicado o algorimo de random forest para regressão e seu tempo de treino era muito grande, assim optamos por remove-lo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a615d6a1",
      "metadata": {},
      "source": [
        "### **1. LinearRegression (baseline)**\n",
        "\n",
        "| Modelo           | MSE                        | R²                       |\n",
        "| ---------------- | -------------------------- | ------------------------ |\n",
        "| LinearRegression | **2.7485636071557513e+30** | **0.003664312908851053** |\n",
        "\n",
        "\n",
        "### **2. XGBRegressor (antes da otimização)**\n",
        "\n",
        "| Modelo       | MSE                        | R²                      |\n",
        "| ------------ | -------------------------- | ----------------------- |\n",
        "| XGBRegressor | **2.6029039949137874e+30** | **0.05646493555651311** |\n",
        "\n",
        "\n",
        "### **3. XGBRegressor (após otimização de hiperparâmetros)**\n",
        "\n",
        "| Modelo                | MSE                        | R²                      |\n",
        "| --------------------- | -------------------------- | ----------------------- |\n",
        "| XGBRegressor (tuning) | **2.5629922196568756e+30** | **0.07093268369961414** |\n",
        "\n",
        "\n",
        "### **4. Validação Cruzada – XGBRegressor Tunado**\n",
        "\n",
        "| Métrica            | Valor                     |\n",
        "| ------------------ | ------------------------- |\n",
        "| MSE médio (CV)     | **2.488458303130407e+30** |\n",
        "| Desvio padrão (CV) | **2.722938114453816e+29** |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9facf55",
      "metadata": {},
      "source": [
        "# Terceiro"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e9845e",
      "metadata": {},
      "source": [
        "Essas são as colunas que devem ser removidas para não haver data leak "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "d8d84c58",
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas = [\n",
        "    'VlrTotPagArr',\n",
        "    'VlrTotDifPvrPagArr',\n",
        "    'prop_pago',\n",
        "    'fatura_paga',\n",
        "    'fatura_atrasado',\n",
        "    'fatura_nao_paga',\n",
        "    'DscSituacaoCredito',\n",
        "    'DscSituacaoArrecadacao',\n",
        "    'DatIncidenciaMultaMora',\n",
        "    'DatGeracaoConjuntoDados',\n",
        "    'AnoArrec',\n",
        "    'MesArrec',\n",
        "    'NumCPFCNPJ',\n",
        "    'QtdDiasEmAtraso'\n",
        "]\n",
        "y3 = df['QtdDiasEmAtraso']\n",
        "X3 = df.drop(columns=colunas)\n",
        "\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "ee7a994e",
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical = X3.select_dtypes(include=['float64','int64','Int64']).columns\n",
        "categorical = X3.select_dtypes(include=['category']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "954f4b9e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['DatGeracaoConjuntoDados', 'Codcvnarr', 'AnmArrecadacao',\n",
              "       'DatVencimentoTitulo', 'DatIncidenciaMultaMora', 'QtdDiasEmAtraso',\n",
              "       'NumCPFCNPJ', 'SigNomAgente', 'DscSituacaoArrecadacao',\n",
              "       'DscSituacaoCredito', 'VlrPcpPrvArr', 'VlrTotPvrArr', 'VlrTotPagArr',\n",
              "       'VlrTotDifPvrPagArr', 'VlrSelic', 'AnoArrec', 'MesArrec', 'fatura_paga',\n",
              "       'fatura_atrasado', 'fatura_nao_paga', 'TrimestreVencimento',\n",
              "       'prop_pago'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "9e73b6c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE (LinearRegression - dias atraso): 7666.393753342452\n",
            "R² (LinearRegression - dias atraso): 0.562489233319342\n"
          ]
        }
      ],
      "source": [
        "lin_reg2 = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', LinearRegression())\n",
        "])\n",
        "\n",
        "lin_reg2.fit(X3_train, y3_train)\n",
        "pred = lin_reg2.predict(X3_test)\n",
        "\n",
        "print(\"MSE (LinearRegression - dias atraso):\", mean_squared_error(y3_test, pred))\n",
        "print(\"R² (LinearRegression - dias atraso):\", r2_score(y3_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7079ccb",
      "metadata": {},
      "source": [
        "Para o problema de prever a quantidade de dias de atraso o erro do modelo foi alto pois mesmo com correções o dataset ainda possui muitos outliers. Em relação a quão bem o modelo explica o dataset, nesse caso seu desempenho foi mais satisfatório que os outros problemas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "02be84db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AnmArrecadacao 4.026191080136604\n",
            "Codcvnarr 2.1946993303403124\n",
            "SigNomAgente 0.9819693884787712\n",
            "VlrSelic 0.49596723423310884\n",
            "VlrPcpPrvArr 0.002290048882192175\n",
            "VlrTotPvrArr 0.0013191213148431747\n",
            "TrimestreVencimento 0.0007060267707272195\n",
            "DatVencimentoTitulo 0.0\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    lin_reg2, X3_test, y3_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X3.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c47868bd",
      "metadata": {},
      "source": [
        "Os resultados mostram que AnmArrecadacao, Codcvnarr e SigNomAgente são as variáveis que mais explicam os dias de atraso, enquanto as demais têm impacto praticamente nulo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "aef7fd54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE (XGBRegressor - dias atraso): 7038.85302734375\n",
            "R² (XGBRegressor - dias atraso): 0.5983021855354309\n"
          ]
        }
      ],
      "source": [
        "xgb_reg2 = Pipeline(steps=[\n",
        "    ('prep', preprocessor),\n",
        "    ('model', XGBRegressor(tree_method='hist', max_depth=5, learning_rate=0.1))\n",
        "])\n",
        "\n",
        "xgb_reg2.fit(X3_train, y3_train)\n",
        "pred = xgb_reg2.predict(X3_test)\n",
        "\n",
        "print(\"MSE (XGBRegressor - dias atraso):\", mean_squared_error(y3_test, pred))\n",
        "print(\"R² (XGBRegressor - dias atraso):\", r2_score(y3_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd991d1",
      "metadata": {},
      "source": [
        "A aplicação do XGBoost melhorou levemente o desempenho na tarefa de prever o atraso, com o erro diminuindo e a explicabilidade do dataset pelo modelo aumentando suavemente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "bcabb10a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SigNomAgente 0.9219543099403381\n",
            "Codcvnarr 0.12213364839553834\n",
            "VlrSelic 0.05116314888000488\n",
            "VlrPcpPrvArr 0.04076278209686279\n",
            "VlrTotPvrArr 0.011851012706756592\n",
            "AnmArrecadacao 0.00501859188079834\n",
            "TrimestreVencimento 0.0018513917922973633\n",
            "DatVencimentoTitulo 0.0\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(\n",
        "    xgb_reg2, X3_test, y3_test, n_repeats=5, random_state=42\n",
        ")\n",
        "\n",
        "importances = result.importances_mean\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "for idx in indices[:20]:\n",
        "    print(X3.columns[idx], importances[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e97f211",
      "metadata": {},
      "source": [
        "Utilizando o XGBoost, Como atributo mais importante para o problema foi o nome do agente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "e5bfa7ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "param_grid_xgb_reg = {\n",
        "    \"model__n_estimators\": [200, 400],\n",
        "    \"model__max_depth\": [4, 6],\n",
        "    \"model__learning_rate\": [0.05, 0.1],\n",
        "    \"model__subsample\": [0.8],\n",
        "    \"model__colsample_bytree\": [0.8]\n",
        "}\n",
        "\n",
        "grid_xgb_reg = GridSearchCV(\n",
        "    estimator=Pipeline(steps=[\n",
        "        ('prep', preprocessor),\n",
        "        ('model', XGBRegressor(\n",
        "            tree_method='hist',\n",
        "            eval_metric='rmse'\n",
        "        ))\n",
        "    ]),\n",
        "    param_grid=param_grid_xgb_reg,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "0a492a61",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Melhores hiperparâmetros XGBRegressor: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.1, 'model__max_depth': 6, 'model__n_estimators': 400, 'model__subsample': 0.8}\n",
            "MSE após tuning: 3353.349365234375\n",
            "R² após tuning: 0.8086289167404175\n"
          ]
        }
      ],
      "source": [
        "grid_xgb_reg.fit(X3_train, y3_train)\n",
        "\n",
        "print(\"Melhores hiperparâmetros XGBRegressor:\", grid_xgb_reg.best_params_)\n",
        "best_xgb_reg = grid_xgb_reg.best_estimator_\n",
        "\n",
        "pred_xgb_tuned = best_xgb_reg.predict(X3_test)\n",
        "\n",
        "print(\"MSE após tuning:\", mean_squared_error(y3_test, pred_xgb_tuned))\n",
        "print(\"R² após tuning:\", r2_score(y3_test, pred_xgb_tuned))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95509fda",
      "metadata": {},
      "source": [
        "Fazendo otimização de hiperparâmetros com GridSearchCV no XGBoostRegressor para prever os dias de atraso o erro médio diminuiu e a explicabilidade do dataset pelo modelo aumentou."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "6eb60559",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE médio (CV): 3752.4252115885415\n",
            "Desvio padrão: 31.582435437249558\n"
          ]
        }
      ],
      "source": [
        "cv_scores_xgb = cross_val_score(\n",
        "    best_xgb_reg,\n",
        "    X3_train,\n",
        "    y3_train,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"MSE médio (CV):\", -cv_scores_xgb.mean())\n",
        "print(\"Desvio padrão:\", cv_scores_xgb.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afffcdf7",
      "metadata": {},
      "source": [
        "Aplicando validação cruazada o modelo obteve um resultados melhores que o desempenho do modelo base e a versão inicial do XGBoost mas um desempenho inferior ao melhor modelo encontrado tunando os hiperparâmetros."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "878a9a74",
      "metadata": {},
      "source": [
        "### **1. LinearRegression (baseline)**\n",
        "\n",
        "| Modelo           | MSE                   | R²                    |\n",
        "| ---------------- | --------------------- | --------------------- |\n",
        "| LinearRegression | **7666.393753342452** | **0.562489233319342** |\n",
        "\n",
        "### **2. XGBRegressor (antes da otimização)**\n",
        "\n",
        "| Modelo       | MSE                  | R²                     |\n",
        "| ------------ | -------------------- | ---------------------- |\n",
        "| XGBRegressor | **7038.85302734375** | **0.5983021855354309** |\n",
        "\n",
        "### **3. XGBRegressor (após otimização de hiperparâmetros)**\n",
        "\n",
        "| Modelo                | MSE                   | R²                     |\n",
        "| --------------------- | --------------------- | ---------------------- |\n",
        "| XGBRegressor (tuning) | **3353.349365234375** | **0.8086289167404175** |\n",
        "\n",
        "### **4. Validação Cruzada – XGBRegressor Tunado**\n",
        "\n",
        "| Métrica        | Valor                  |\n",
        "| -------------- | ---------------------- |\n",
        "| MSE médio (CV) | **3752.4252115885415** |\n",
        "| Desvio padrão  | **31.582435437249558** |\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
